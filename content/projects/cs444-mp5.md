+++
authors = ["Ziheng Chen"]
title = "ML: Deep Reinforcement Learning"
date = "2023-05-05"
tags = [
    "python", "pytorch", "numpy", "reinforcement-learning", "machine-learning", "deep-learning", "neural-networks",
    "matplotlib"
]
aliases = ["cs444-mp5"]
+++

[Source (GitHub)](https://github.com/zihengjackchen/CS444-Deep-Learning/tree/main/assignment5%20-%20Deep%20Reinforcement%20Learning)

#### Contributions
- Implemented Deep Q-Network (DQN) and its successor Double DQN for playing Atari Breakout using OpenAI - Gym
- Developed a recurrent state mechanism to encode and maintain a history of actions and observations
- Managed hyperparameters through "config.py" to achieve a mean score of 10 within computational limitations (around 2000 episodes)
- Monitored and debugged progress using expected rewards versus the number of episodes as a benchmark
- Demonstrated problem-solving and experimentation skills within the constraints outlined in the assignment
- Successfully contributed to achieving the target evaluation score of 10 for either "agent.py" or - "agent_double.py"

#### Project Overview
As part of this project, I am developing a computer program capable of playing the classic Atari Breakout game. To achieve this, I am utilizing techniques from the field of deep reinforcement learning, specifically the Deep Q-Network (DQN) and its enhanced version, Double DQN.

The primary objectives of this project are twofold: firstly, to gain a comprehensive understanding of how these techniques operate with detailed visual information from the game, and secondly, to establish a system that effectively retains the game's progress.

The project begins with provided initial code and a helpful guide in a notebook named "MP5.ipynb," guiding me through the setup of DQN and Double DQN. My focus is on training the computer agent using two separate files: "agent.py" for DQN and "agent_double.py" for Double DQN. It is crucial not to alter the configuration of the computer's neural network, as this is essential for evaluation.

Given the constraints of my computer's processing power, the expected performance is to achieve an average score of 10 after approximately 2000 rounds of gameplay. While I have the option to adjust hyperparameters in "config.py," the default settings should be sufficient to reach the specified goal.

For the purpose of this project, each round of gameplay is referred to as an episode, and the agent is granted five lives. Although I cannot run the program for 30 minutes, as mentioned in the research paper, this deviation is acceptable for this assignment.

To monitor progress, specific performance benchmarks have been provided. For example, after 200 episodes, the expected score should be around 1.5. My ultimate objective is to ensure that either "agent.py" or "agent_double.py" attains a score of 10. To maintain fairness, both files must be run for the same number of episodes, with the target score only needing to be achieved by one of them.

[Assignment Page](https://slazebni.cs.illinois.edu/spring23/assignment5.html)







